---
title: "Assigning ASVs to Snail Microbiome Trimmed Data"
author: "Daphne Garcia"
date: "2025-03-12"
output: html_document
editor_options: 
  chunk_output_type: console
---


#Setting the seed
```{r set seed}

# Any number can be chosen 
set.seed(238428)

n_threads = 20
```

#Timing
```{r}
# What time did we start running this script? 
start_time <- Sys.time()
start_time
```

#Load Libraries
```{r}
pacman::p_load(tidyverse, devtools, dada2, 
               patchwork, DT, install = FALSE)
```

#Load in Filtered fastqs
```{r load filtered fastqs}
# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "data/data_filtered"

# Intuition Check 
filtered_fastqs_path


# create 2 vectors: filtered_forward_reads & filtered_reverse_reads
filtered_forward_reads <- 
  list.files(filtered_fastqs_path, pattern = "_R1_filtered.fastq.gz",
             full.names = TRUE)  

# reverse reads
filtered_reverse_reads <- 
    list.files(filtered_fastqs_path, pattern = "_R2_filtered.fastq.gz",
             full.names = TRUE)  

# Intuition Checks
length(filtered_forward_reads)
length(filtered_reverse_reads)
```
# Assign Sample Names
```{r Assign sample names}
sample_names <- sapply(strsplit(basename(filtered_forward_reads), "_"), `[`,1) 

# Intuition Check 
head(sample_names)
```

#Learn the errors: MiSeq Runs: 40 Phred Scores
```{r Miseq rins: 40 phred scores}
# Forward Reads 
error_forward_reads <- 
  learnErrors(filtered_forward_reads, multithread = n_threads)

forward_error_plot <- 
  plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Reads: Error Model")



# Reverse Reads 
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads, multithread = n_threads)

reverse_error_plot <- 
  plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Reads: Error Model")


# Look at the plots together 
forward_error_plot + reverse_error_plot
```

# Infer ASVs on forward sequences
```{r infer ASVs on forward sequences}
# Infer ASVs on the forward sequences
dada_forward <- 
  dada(filtered_forward_reads, 
       err = error_forward_reads,
       multithread = n_threads) 
```
## Intuition checks for forward ASVs infererence
```{r}
typeof(dada_forward) # It's a list 
length(dada_forward) # How big is it? One per sample!
dada_forward$`SRR19509095_R1_filtered.fastq.gz` #D note: name of first of list
```

# Infer ASVs on reverse sequences
```{r}
dada_reverse <- 
  dada(filtered_reverse_reads,
       err = error_reverse_reads ,
       multithread = n_threads)
```

## Intuition checks for reverse ASVs infererence
```{r}
typeof(dada_reverse) # It's a list 
length(dada_reverse) # How big is it? One per sample!
dada_reverse$`SRR19509095_R2_filtered.fastq.gz` #D note: name of first of list
```

# Merge Forward and Reverse ASVs
```{r merge forward and reverse ASVs}
merged_ASVs <- 
  mergePairs(dada_forward, filtered_forward_reads,
             dada_reverse, filtered_reverse_reads,
             verbose = TRUE)
```


## Intuition checks for merging
```{r}
typeof(merged_ASVs) # It's a list 
length(merged_ASVs) # How big is it? One per sample!
head(names(merged_ASVs)) # Here, we can access our current sample names (all R1)


# Inspect further for each sample
#head(merged_ASVs, n = 2) # A dataframe for each sample
# We have a dataframe in each part of our list! What are in the columns? 
glimpse(merged_ASVs$`SRR19509149_R1_filtered.fastq.gz`)
```


#Create Raw ASV Count Table
```{r create raw ASV count table}
# Raw ASV
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Intuition Check: Type and dimensions of the data
dim(raw_ASV_table)

typeof(raw_ASV_table)
class(raw_ASV_table)

# write out raw_asv_table 
write.table(raw_ASV_table, file = "data/data_filtered/raw_ASV_counts.tsv",
            sep = "\t", quote = FALSE, col.names = NA)
```


INTERPRETATION #1

1. Sequencing strategy: Illumina NovaSeq 6000 paired end 2x250. Specifically, 341F and 806R so 1 - (806-341)/(2x250) = 7% overlap. 
2. 806-341 = 465, with primers
3. The paper used primers: 314 Forward (5′-CCTAYGGGRBGCASCAG-3′), 806 Reverse (5′GGACTACNNGGGTATCTAAT-3′), which are 17 and 20 respectively. 465 - 17 - 20 = 428

Therefore, I expect the ASV length without primers to be 428 bp long

4. The length of trimmed ASVs: Since there were adapters before the primers of different lengths, I had to I used trimLeft =c(23,26) instead of 17 and 20. I also used truncLen = c(250,247), Therefore, 465 - 23 - 26 - 3 = 413
5. from the multiQC report: "All samples have sequences of a single length (250bp)". Therefore, if the legnth of trimmed reads is 413, overlap is 34.8%

#ASV Length Stats
```{r}
# Calculate summary stats
# Longest ASV?
maxLength_ASV <- max(nchar(getSequences(raw_ASV_table)))

# Shortest ASV?
minLength_ASV <- min(nchar(getSequences(raw_ASV_table))) 

# Mean ASV length?
meanLength_ASV <- mean(nchar(getSequences(raw_ASV_table))) 

# Median ASV length?
medianLength_ASV <- median(nchar(getSequences(raw_ASV_table))) 

# Create a table to Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table)))
```

# ASV length plot RAW
```{r}
# Inspect the distribution of sequence lengths of all ASVs in data set 
# AFTER TRIM
plot_ASVLength_raw <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Raw ASV Length (bps)")

# Show the plot
plot_ASVLength_raw
```

INTERPRETATION #2

The table's most abundant ASV length is 429 (112k reads), which is also the median, which matches the raw ASV length plot. This matches the non-primer pre-trimmed estimate of reads, which is 428. However, this does not match the post trimming estimate of the read length, which is 413. I'm not completely sure why, and I'm not sure I estimated the ASV lengths correctly in interpretation 1. Additionally, there are 12k reads at length 425, which is also unexpected.


INTEPRETATION #3

Taking into account the previous two interpretations, I will trim to the a range of lengths between 425 and 430, since the ASV length of 429 forms a clear peak in the ASV length plot, but 425 and 430 also have relatively higher abundances compared to the rest of the sequences.

** Also, I originally tried trimming to exact length of 429, and only got a 67% retention rate

# Trim ASV lengths
```{r}
# Subset only ASVs that are between 425 and 430 (chatgpt)
raw_ASV_table_trimmed <- 
  raw_ASV_table[, nchar(colnames(raw_ASV_table)) >= 424 & nchar(colnames(raw_ASV_table)) <= 430]

# Inspect the distribution of sequence lengths of all ASVs in dataset 
table(nchar(getSequences(raw_ASV_table_trimmed)))

# What proportion of total ASV sequences are left in the data? 
percRetained_Trimmed <- sum(raw_ASV_table_trimmed)/sum(raw_ASV_table)
percRetained_Trimmed # Show it 
```
When I'm trimming everything that isn't 429, I get 67.8%
When I trim a range between 424 and 430 (424 has 12K and 430 has 9k ASVs), percent retained = 88.2%

# Inspect distribution of seq lengths after trim
```{r}
# Inspect the distribution of sequence lengths of all ASVs in dataset 
# AFTER TRIM
plot_ASVLength_trimmed <- 
  data.frame(Seq_Length = nchar(getSequences(raw_ASV_table_trimmed))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs", x = "Trimmed ASV Length (bps)")

# Show the plot 
plot_ASVLength_trimmed

```

#Removing Chimeras
```{r}
# Remove the chimeras in the raw ASV table
noChimeras_ASV_table <- 
  removeBimeraDenovo(raw_ASV_table_trimmed, 
                     method="consensus", 
                     multithread = n_threads, 
                     verbose=TRUE)

# Check the dimensions
dim(noChimeras_ASV_table)

```
(bimera is two parent chimera)

```{r}
# What proportion is left of the sequences? 
# Chimera removal compared to trimming  0.75
percRetained_chimerasTrimmed <- sum(noChimeras_ASV_table)/sum(raw_ASV_table_trimmed)
# Chimera removal compared to raw   0.67
percRetained_chimerasRaw <-sum(noChimeras_ASV_table)/sum(raw_ASV_table)
```
Chimera removal compared to trimming  0.7598
Chimera removal compared to raw   0.6702

```{r}
# Plot it 
plot_ASVLength_NoChimeras <- 
  data.frame(Seq_Length_NoChim = nchar(getSequences(noChimeras_ASV_table))) %>%
  ggplot(aes(x = Seq_Length_NoChim )) + 
  geom_histogram()+ 
  # include the x-axis scales
  scale_x_continuous(limits = c(0, maxLength_ASV + 5)) + 
  labs(y = "Number of ASVs \n (Post-Chimera Removal)", 
       x = "ASV Length (bps)")

# Show the plot
plot_ASVLength_NoChimeras 
```
INTERPRETATION #4


1. 88.2% of the raw ASVs were retained after trimming, using the range of lengths 422 and 430.
2. 75.98% of the trimmed ASV counts were retained after chimera removal
3. This translates to 67.01% retention of the original, raw merged ASV counts after both trimming and chimera removal. This is confirmed by variable percRetained_chimerasRaw, which calculated a 67.02% chimera removal. 
I feel like the chimeral removal for whatever reason is losing too many samples, and the following analyses will not be representative of the full 



3. After trimming and chimeral removal, only 67% of reads were retained

# Plot ASV Lengths
```{r}
plot_ASVLength_raw + plot_ASVLength_trimmed + plot_ASVLength_NoChimeras + 
    plot_annotation(tag_levels = 'A')
```

#Track read counts
```{r}
# A little function to identify number seqs 
getN <- function(x) sum(getUniques(x))

# Make the table to track the seqs 
track <- cbind(sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_ASVs, getN),
               rowSums(noChimeras_ASV_table))

head(track)
```

```{r}
# Update column names to be more informative (most are missing at the moment!)
colnames(track) <- c("denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- row.names(noChimeras_ASV_table)

# Generate a dataframe to track the reads through our DADA2 pipeline
track_counts_df <- 
  track %>%
  # make it a dataframe
  as.data.frame() %>%
  rownames_to_column(var = "sample_names")

# Now let's add a column for the number of ASVs
# First, intuition check that the samples match 
stopifnot(track_counts_df$sample_names == row.names(noChimeras_ASV_table))

# Now, let's add a new column with the number of ASVs
track_counts_df <- 
  track_counts_df %>%
  mutate(num_ASVs = rowSums(noChimeras_ASV_table > 1))

# Visualize it in table format 
DT::datatable(track_counts_df)
```

# Plotting track counts
```{r}
# Plot it!
track_counts_df %>%
  pivot_longer(denoisedF:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  geom_line(aes(group = sample_names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Filtering Step", y = "Number of Sequences") + 
  theme_bw()
```

# Plotting number of maintained seq 
```{r}
plot_ReadDepth <- 
  track_counts_df %>%
  ggplot(aes(x = nochim)) + 
  geom_histogram() + 
  labs(x = "Total # of Sequences", y = "# of Samples") + 
  theme_bw()

# What is the ASV richness per sample? 
plot_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = num_ASVs)) + 
  geom_histogram() + 
  labs(x = "Total # of ASVs", y = "# of Samples") + 
  theme_bw()

# Now, let's look at the relationship of ASVs and Sequencing depth 
plot_ReadDepth_ASVRichness <- 
  track_counts_df %>%
  ggplot(aes(x = nochim, y = num_ASVs)) + 
  geom_point() + 
  labs(x = "Total # of Sequences", y = "# of ASVs") + 
  theme_bw()

# Show the plots together 
plot_ReadDepth + plot_ASVRichness + plot_ReadDepth_ASVRichness + 
    plot_annotation(tag_levels = 'A')
```

INTERPRETATION #5

Panel A: ASV Depth after DADA2 Histogram of sequencing depth per sample (Total # of Sequences)

The distribution is a wide unimodal curve. There is a center around 60,000, with three peaks around 55,000 60,000 and 70,000 reads per sample.
There are a couple of outliers that have less than 50,000, and one sample that has a very high sequencing depth: almost 80,000.


Panel B: ASV Richness after DADA2: Histogram of ASV richness (Total # of ASVs per sample)

This distribution I'd say is bimodal. There is a peak of 8 samples that either have 500 ASVs or 700 ASVs. There's a steep decline of samples that have less than 500 ASVs, which may correspond to the multiple outliers in panel A that have low sequencing depth. There are a couple of outlier that have over 800 ASVs (up to 1250), which is exciting.


Panel C: Read Depth vs ASV Richness: Scatter plot showing the relationship between sequencing depth and ASV richness.

I would expect a positive correlation between higher read depth and more ASVs, however that doesn't seem to be the case in my scatterplot. There is no correlation between number of sequences and number of ASVs. Generally, most points are below 750 ASV's, regardless of number of sequences, and there's 7 outliers that have over 750 ASVs. There's also quite a few samples below 500 ASV's, which I wasn't able to see in panel B.

Overall Interpretation & Considerations:

Sequencing depth variation: Most samples are spread among a range of common sequencing depths, but there are a few sequences that are undersequenced.

ASV richness does not distinctly read depth trends: When viewing the scatterplot, there seems to be no correlation between number sequencing depth (num sequences) and richness (num ASVs), 
Rarefaction or normalization may definitely be needed, to hopefully standardize the read depth, as there is a range of depths. Since the plots do not suggest that richness is correlated or affected by read depth, rarefying might not have as large of an effect. What may be happening is that there may just be incredibly variable variation in snail microbiomes, but further analysis will be needed to assert what is going on.
